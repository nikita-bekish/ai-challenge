import OpenAI from "openai";

const hfClient = new OpenAI({
  baseURL: "https://router.huggingface.co/v1",
  apiKey: process.env.HF_API_TOKEN,
});

export async function generateCompletion_HuggingFaceRouter({ messages }) {
  const start = Date.now();

  try {
    const response = await hfClient.chat.completions.create({
      model: "HuggingFaceH4/zephyr-7b-beta",
      temperature: 0.7,
      messages,
    });

    const end = Date.now();
    const duration = ((end - start) / 1000).toFixed(2);

    const answer = response.choices[0].message.content;
    const tokens = response.usage?.total_tokens ?? "N/A";

    const result = `üß† –ú–æ–¥–µ–ª—å: Xenova/gpt-3.5-turbo
                    ‚è± –í—Ä–µ–º—è: ${duration}s
                    üßÆ –¢–æ–∫–µ–Ω—ã: ${tokens}

                    üí¨ ${answer}
                    `;
    return result;
  } catch (error) {
    console.error("‚ùå –û—à–∏–±–∫–∞ Xenova/gpt-3.5-turbo:", error.message);
    return `‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Sao10K/L3-8B-Stheno-v3.2`;
  }
}
