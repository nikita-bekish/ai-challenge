//import dotenv from "dotenv";
import * as tokenizer from "gpt-tokenizer";
import OpenAI from "openai";

// dotenv.config();

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function generateCompletion_OpenAI({ messages, format }) {
  const start = Date.now();

  // ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
  const inputText = messages
    .map((msg) => `${msg.role}: ${msg.content}`)
    .join("\n");
  const inputTokens = tokenizer.encode(inputText).length;

  const systemByFormat = {
    json: `You are a professional AI that always responds in strict JSON format.
Do not include explanations or markdown.
Return only a valid JSON object matching this schema:
{ "title": "string", "summary": "string", "key_points": ["string", "string", "string"] }`,
    markdown: `You are a professional AI that always responds in clean Markdown.
Format your answer as follows:

# {title}

**Summary:** {summary}

## Key Points
- {point1}
- {point2}
- {point3}

Do not include JSON or extra commentary.`,
  };

  const systemPrompt =
    format && (format === "json" || format === "markdown")
      ? systemByFormat[format]
      : null;

  const payload = systemPrompt
    ? [{ role: "system", content: systemPrompt }, ...messages]
    : messages;

  // ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ system prompt ĞµÑĞ»Ğ¸ Ğ¾Ğ½ ĞµÑÑ‚ÑŒ
  let systemPromptTokens = 0;
  if (systemPrompt) {
    systemPromptTokens = tokenizer.encode(systemPrompt).length;
  }

  const resp = await client.chat.completions.create({
    model: "gpt-4o-mini",
    temperature: 0,
    messages: payload,
    max_completion_tokens: 2048,
  });

  const end = Date.now();
  const duration = ((end - start) / 1000).toFixed(2);

  // ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ»Ğ¸ summary Ğ² Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğµ
  const hasSummary = messages.some(
    (msg) =>
      msg.role === "system" &&
      msg.content.includes("ĞŸÑ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° (summary)")
  );
  const summaryStatus = hasSummary ? "ğŸ“ Ğ¡ SUMMARY" : "ğŸ“‹ Ğ‘Ğ•Ğ— SUMMARY";

  const totalInputTokens = inputTokens + systemPromptTokens;
  const openaiPromptTokens = resp.usage?.prompt_tokens ?? 0;
  const completionTokens = resp.usage?.completion_tokens ?? 0;

  const result = `${summaryStatus}
ğŸ§  ĞœĞ¾Ğ´ĞµĞ»ÑŒ: gpt-4o-mini
â± Ğ’Ñ€ĞµĞ¼Ñ: ${duration}s

ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ¢ĞĞšĞ•ĞĞĞ’:
  ğŸ’­ Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ: ${inputTokens}
  ğŸ”§ System prompt: ${systemPromptTokens}
  ğŸ“ ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ²Ñ…Ğ¾Ğ´: ${totalInputTokens}
  ğŸ§® OpenAI Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚: ${openaiPromptTokens}
  âœï¸ Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ: ${completionTokens}
  ğŸ“ˆ ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ€Ğ°ÑÑ…Ğ¾Ğ´: ${openaiPromptTokens + completionTokens}

ğŸ’¬ ${resp.choices[0].message.content}`;
  return result;
}
